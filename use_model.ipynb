{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe0310b-85f1-4d02-a55e-f1579f97c7b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:47:29.189188Z",
     "iopub.status.busy": "2023-06-06T19:47:29.188899Z",
     "iopub.status.idle": "2023-06-06T19:47:29.193921Z",
     "shell.execute_reply": "2023-06-06T19:47:29.193158Z",
     "shell.execute_reply.started": "2023-06-06T19:47:29.189165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import chabud\n",
    "from chabud import BandExtractor, NBR, NDVI, GNDVI, EVI, AVI, SAVI, NDMI, MSI, GCI, BSI, NDWI, NDSI, NDGI\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import xarray as xr\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import pandas as pd\n",
    "from trimesh.voxel.runlength import dense_to_brle\n",
    "from collections import defaultdict\n",
    "\n",
    "from typing import Any, Union, Dict, Literal\n",
    "from typing import List, Tuple\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37b60bf-4f22-4e42-a357-fb8cd287c67e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T18:55:06.677702Z",
     "iopub.status.busy": "2023-06-06T18:55:06.675967Z",
     "iopub.status.idle": "2023-06-06T18:55:06.682021Z",
     "shell.execute_reply": "2023-06-06T18:55:06.681136Z",
     "shell.execute_reply.started": "2023-06-06T18:55:06.677677Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASEDIR = Path(\"/global/public/chabud-ecml-pkdd2023/\")\n",
    "fn = BASEDIR / \"train_eval.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b66370-12b7-4b45-a8a8-8e9f5d204c26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T18:55:06.686113Z",
     "iopub.status.busy": "2023-06-06T18:55:06.684667Z",
     "iopub.status.idle": "2023-06-06T18:55:06.689888Z",
     "shell.execute_reply": "2023-06-06T18:55:06.688957Z",
     "shell.execute_reply.started": "2023-06-06T18:55:06.686090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show checkpoints\n",
    "#CHECK_BASEDIR = Path(\"./lightning_logs/version_9\")\n",
    "\n",
    "#CHECKPOINTDIR = CHECK_BASEDIR / \"checkpoints\"\n",
    "\n",
    "#list(CHECKPOINTDIR.glob(\"*.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231aa552-666e-44d9-8c37-d1ef9913edbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T18:55:06.694728Z",
     "iopub.status.busy": "2023-06-06T18:55:06.693132Z",
     "iopub.status.idle": "2023-06-06T18:55:07.061807Z",
     "shell.execute_reply": "2023-06-06T18:55:07.061163Z",
     "shell.execute_reply.started": "2023-06-06T18:55:06.694705Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = chabud.FireModel.load_from_checkpoint(Path('lightning_logs/version_9/checkpoints/epoch=39-step=1040.ckpt'), map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ec1199-0d61-4a6f-ac62-5240cec88fcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T18:55:07.066462Z",
     "iopub.status.busy": "2023-06-06T18:55:07.064935Z",
     "iopub.status.idle": "2023-06-06T18:55:07.071948Z",
     "shell.execute_reply": "2023-06-06T18:55:07.071072Z",
     "shell.execute_reply.started": "2023-06-06T18:55:07.066437Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_submission_mask(id: str, mask: NDArray):\n",
    "    brle = dense_to_brle(mask.astype(bool).flatten())\n",
    "    return {\"id\": id, \"rle_mask\": brle, \"index\": np.arange(len(brle))}\n",
    "\n",
    "def obtain_submission_df(submissions: Dict[str, NDArray]) -> pd.DataFrame:\n",
    "    res = []\n",
    "    for uuid, prediction in submissions.items():\n",
    "      submission_mask = compute_submission_mask(uuid, prediction)\n",
    "      res.append(pd.DataFrame(submission_mask))\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "305b7eaf-8e3a-4612-b16a-ee73c40bc843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T18:55:07.076392Z",
     "iopub.status.busy": "2023-06-06T18:55:07.074834Z",
     "iopub.status.idle": "2023-06-06T18:55:07.083604Z",
     "shell.execute_reply": "2023-06-06T18:55:07.082839Z",
     "shell.execute_reply.started": "2023-06-06T18:55:07.076369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_xarray(dataset, pretty_band_names=True):\n",
    "    \"\"\"Convert a single example into an xarray for easy access\"\"\"\n",
    "    \n",
    "    if pretty_band_names:\n",
    "        BANDS = [\"coastal_aerosol\", \"blue\", \"green\", \"red\",\n",
    "                 \"veg_red_1\", \"veg_red_2\", \"veg_red_3\", \"nir\", \n",
    "                 \"veg_red_4\", \"water_vapour\", \"swir_1\", \"swir_2\"]\n",
    "    else:\n",
    "        BANDS = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"8a\", \"9\", \"11\", \"12\"]\n",
    "        \n",
    "    post = dataset[\"post_fire\"][...].astype(\"float32\") / 10000.0\n",
    "    \n",
    "    # Da `pre_fire` manchmal fehlt ersetzen wir es durch 0 Werte was\n",
    "    # eh der Platzhalter für einen fehlenden Messwert ist.\n",
    "    try:\n",
    "        pre = dataset[\"pre_fire\"][...].astype(\"float32\") / 10000.0\n",
    "    except KeyError:\n",
    "        pre = np.zeros_like(post, dtype=\"float32\")\n",
    "        \n",
    "    # Da die Maske nur ein \"Band\" hat können wir die dritte Dimension einfach\n",
    "    # weglassen. Das erreichen wir in dem wir mit `0` am Ende indizieren.\n",
    "    mask = dataset[\"mask\"][..., 0].astype(\"bool\")\n",
    "    \n",
    "    return {\"pre\": xr.DataArray(pre, dims=[\"x\", \"y\", \"band\"], coords={\"x\": range(512), \"y\": range(512), \"band\": BANDS}),\n",
    "            \"post\": xr.DataArray(post, dims=[\"x\", \"y\", \"band\"], coords={\"x\": range(512), \"y\": range(512), \"band\": BANDS}),\n",
    "            \"mask\": xr.DataArray(mask, dims=[\"x\", \"y\"], coords={\"x\": range(512), \"y\": range(512)}),\n",
    "            \"fold\": dataset.attrs[\"fold\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4b06b8-eaca-47e1-b18e-36069b4cf064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T18:55:07.088006Z",
     "iopub.status.busy": "2023-06-06T18:55:07.086499Z",
     "iopub.status.idle": "2023-06-06T18:55:07.093516Z",
     "shell.execute_reply": "2023-06-06T18:55:07.092640Z",
     "shell.execute_reply.started": "2023-06-06T18:55:07.087983Z"
    }
   },
   "outputs": [],
   "source": [
    "class PPModel:\n",
    "    def _init_(self, model):\n",
    "        self._model = model\n",
    "        self._model.eval()\n",
    "        \n",
    "    def _call_(self, bands) -> Any:\n",
    "        # preprocessing\n",
    "        bands = bands / 10000\n",
    "        channels = np.stack([c(bands) for c in self._model.channels])\n",
    "        channels = torch.Tensor(channels())\n",
    "        # Modell auswerten\n",
    "        with torch.set_grad_enabled(False):\n",
    "            mask = self.model.forward(channels.sigmoid() > 0.5)\n",
    "        # Postprocessing\n",
    "        mask = mask[0, 0, ...].detach.numpy()\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef366c4-92b1-49e8-af95-46fe430b68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(bands, true):\n",
    "    channels = np.stack([c(bands) for c in mdl.channels])\n",
    "    with torch.set_grad_enabled(False):\n",
    "        pred = mdl.forward(torch.Tensor(channels[np.newaxis, ...])).sigmoid() > 0.5\n",
    "        pred = pred[0, 0, ...].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0b6972f-9d7f-4a9c-8cef-d23ba6e640ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-06T19:52:52.567740Z",
     "iopub.status.busy": "2023-06-06T19:52:52.566031Z",
     "iopub.status.idle": "2023-06-06T19:52:57.815311Z",
     "shell.execute_reply": "2023-06-06T19:52:57.813621Z",
     "shell.execute_reply.started": "2023-06-06T19:52:52.567714Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 5, 78, 512, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m channels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([c(loader()) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mchannels])\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 35\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msigmoid() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     36\u001b[0m     pred \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# convert the prediction in RLE format\u001b[39;00m\n",
      "File \u001b[0;32m~/datamining/chabud.py:451\u001b[0m, in \u001b[0;36mFireModel.forward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m--> 451\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:29\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m---> 29\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m     32\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/resnet.py:62\u001b[0m, in \u001b[0;36mResNetEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mstages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/mambaforge/envs/py310-dm/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 5, 78, 512, 512]"
     ]
    }
   ],
   "source": [
    "def loader():\n",
    "    post = []\n",
    "\n",
    "    # Read hdf5 file and filter by fold\n",
    "    with h5py.File(fn, \"r\") as fd:\n",
    "        for uuid, values in fd.items():\n",
    "            if values.attrs['fold'] != 0:\n",
    "                continue                  \n",
    "            if \"pre_fire\" not in values:\n",
    "                continue\n",
    "\n",
    "            post.append(values[\"post_fire\"][...])\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    post = np.stack(post, axis=0, dtype=np.int32)\n",
    "    return post\n",
    "\n",
    "def compute_submission_mask(id: str, mask: NDArray):\n",
    "    brle = dense_to_brle(mask.astype(bool).flatten())\n",
    "    return {\"id\": id, \"rle_mask\": brle, \"index\": np.arange(len(brle))}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    validation_fold = loader()\n",
    "    # use a list to accumulate results\n",
    "    result = []\n",
    "    # instantiate the model\n",
    "    model = chabud.FireModel.load_from_checkpoint(Path('lightning_logs/version_9/checkpoints/epoch=39-step=1040.ckpt'), map_location=\"cpu\")\n",
    "    #for uuid,item in validation_fold:\n",
    "        # model.forward()\n",
    "        # perform the prediction\n",
    "        # print(input_images['post'].shape)\n",
    "        \n",
    "    channels = np.stack([c(loader()) for c in model.channels])\n",
    "    with torch.set_grad_enabled(False):\n",
    "        pred = model.forward(torch.Tensor(channels[np.newaxis, ...])).sigmoid() > 0.5\n",
    "        pred = pred[0, 0, ...].detach().numpy()\n",
    "        # convert the prediction in RLE format\n",
    "        encoded_prediction = compute_submission_mask(uuid, pred)\n",
    "        result.append(pd.DataFrame(encoded_prediction))\n",
    "\n",
    "    # concatenate all dataframes\n",
    "    submission_df = pd.concat(result)\n",
    "    submission_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986c60e-858b-4a6d-8811-e52c259b12c9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-06T18:55:07.604475Z",
     "iopub.status.idle": "2023-06-06T18:55:07.606031Z",
     "shell.execute_reply": "2023-06-06T18:55:07.605879Z",
     "shell.execute_reply.started": "2023-06-06T18:55:07.605860Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#class PPModel:\n",
    "#    def _init_(self, model):\n",
    "#        self._model = model\n",
    "#        self._model.eval()\n",
    "        \n",
    "#    def _call_(self, inut) -> Any:\n",
    "        #Preprocessing\n",
    "#        bands = bands / 10000\n",
    "#        channels = np.stack([])\n",
    "#        mask_logits = self._model.forward(input)\n",
    "        # Mein PP\n",
    "        \n",
    "#        return mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 / DM",
   "language": "python",
   "name": "py310-dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
